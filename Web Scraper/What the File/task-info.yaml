type: edu
custom_name: What the File?
files:
- name: scraper.py
  visible: true
  text: |
    import requests
    from bs4 import BeautifulSoup


    def get_quota(quota_url):
        response = requests.get(quota_url)
        try:
            return response.json()['content']
        except KeyError:
            return 'Invalid quote resource!'


    def get_nature_article(page_url):
        if 'nature' not in page_url:
            return 'Invalid page!'
        r = requests.get(page_url)
        soup = BeautifulSoup(r.content, 'html.parser')
        try:
            title = soup.find('title').text
            meta = soup.find('meta', {'name': 'description'}).get('content')
            return {"title": title, "description": meta}
        except KeyError:
            return 'Invalid page!'


    url = input("Input the URL:")
    resp = get_nature_article(url)
    print(resp)
  learner_created: false
- name: test/__init__.py
  visible: false
  learner_created: false
- name: test/tests.py
  visible: false
  text: |
    import requests
    from hstest.check_result import CheckResult
    from hstest.stage_test import StageTest
    from hstest.test_case import TestCase


    class WebScraperTest(StageTest):
        def generate(self):
            return [TestCase(stdin="https://www.ikea.com/404",
                             check_function=self.check_not_200,
                             attach="https://www.ikea.com/404", time_limit=0),
                    TestCase(stdin="http://httpstat.us/403",
                             check_function=self.check_not_200,
                             attach="http://httpstat.us/403", time_limit=0),
                    TestCase(
                        stdin='http://www.pythonchallenge.com/pc/def/0.html',
                        check_function=self.check_200,
                        attach="http://www.pythonchallenge.com/pc/def/0.html", time_limit=0)]

        def check_200(self, reply, attach):
            try:
                test_content = requests.get(attach).content
            except Exception:
                return CheckResult.wrong("An error occurred when tests tried to connect to the Internet page.\n"
                                         "Please, try again.")
            try:
                with open("source.html", "rb") as f:
                    file_content = f.read()
                    if file_content == test_content:
                        return CheckResult.correct() if "Content saved" in reply and "The URL returned" not in reply \
                            else CheckResult.wrong("Did you notify the user you've saved the content?")
                    else:
                        return CheckResult.wrong("The content of the file is not correct!")
            except FileNotFoundError:
                return CheckResult.wrong("Couldn't find the source.html file")

        def check_not_200(self, reply, attach):
            try:
                status_code = requests.get(attach).status_code
            except Exception:
                return CheckResult.wrong("An error occurred when tests tried to connect to the Internet page.\n"
                                         "Please, try again.")
            if f"The URL returned" in reply and "Content saved" not in reply:
                if str(status_code) in reply:
                    return CheckResult.correct()
                else:
                    return CheckResult.wrong("The returned error doesn't match with the output message.")
            else:
                return CheckResult.wrong("The link returned an error, but your program didn't.")


    if __name__ == '__main__':
        WebScraperTest().run_tests()
  learner_created: false
- name: tests.py
  visible: false
  text: |
    from test.tests import WebScraperTest

    if __name__ == '__main__':
        WebScraperTest().run_tests()
  learner_created: false
- name: source.html
  visible: true
  learner_created: true
feedback_link: https://hyperskill.org/learn/step/11757#comment
status: Solved
feedback:
  message: Congratulations!
  time: "Sun, 19 Feb 2023 23:23:59 UTC"
record: 3
